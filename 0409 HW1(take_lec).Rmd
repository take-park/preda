---
title: '0409 HW1'
author: "take"
date: '2021 4 13 '
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


## Libraries

```{r load_lib, message=FALSE, warning=FALSE, results='hide'}
library(tidymodels)
library(tidyverse)
library(magrittr)
library(skimr)
library(knitr)
theme_set(theme_bw())
```

## Data load

```{r}
file_path <- "./HousePrices_ART/"
files <- list.files(file_path)
files
```

```{r, message=FALSE}
train <- read_csv(file.path(file_path, "train.csv")) %>% 
  janitor::clean_names()
test <- read_csv(file.path(file_path, "test.csv")) %>% 
  janitor::clean_names()
```


# Data overview {.tabset .tabset-fade}

## Basic info.

```{r}
dim(train)
dim(test)
```

## Distribution of sale_price

```{r message=FALSE, class.source = 'fold-hide'}
train %>% 
  ggplot(aes(x = sale_price)) +
  geom_histogram()
```

log() will save us.

```{r message=FALSE, class.source = 'fold-hide'}
train %>% 
  ggplot(aes(x = log(sale_price))) +
  geom_histogram()
```

# Outliers {.tabset .tabset-fade}

## gr_liv_area variable

* Any thoughts about right 4 points?
  
```{r class.source = 'fold-hide'}
train %>% 
  ggplot(aes(x = gr_liv_area, 
             y = log(sale_price))) +
  geom_point(alpha = 0.6) +
  labs(title = "Before removing outliers")
```

```{r}
# outliers : gr_liv_area > 4500, 2개
train %>%
  filter(gr_liv_area > 4500) %>%
  DT::datatable(width = "100%",  
                options = list(scrollX = TRUE))
# outliers remove
train %<>% filter(!(gr_liv_area > 4500))
```

```{r class.source = 'fold-hide'}
train %>% 
  ggplot(aes(x = gr_liv_area, 
             y = log(sale_price))) +
  geom_point(alpha = 0.6) +
  labs(title = "After removing outliers(2개)")
```

## total_bsmt_sf variable

```{r class.source = 'fold-hide'}
train %>% 
  ggplot(aes(x = total_bsmt_sf, 
             y = log(sale_price))) +
  geom_point(alpha = 0.6) +
  labs(title = "Before removing outliers")
```

```{r}
# outliers : total_bsmt_sf > 3000, 3개
train %>%
  filter(total_bsmt_sf > 3000) %>%
  DT::datatable(width = "100%",  
                options = list(scrollX = TRUE))
# outliers remove
train %<>% filter(!(total_bsmt_sf > 3000))
```

```{r class.source = 'fold-hide'}
train %>% 
  ggplot(aes(x = total_bsmt_sf, 
             y = log(sale_price))) +
  geom_point() +
  labs(title = "After removing outliers(3개)")
```

## garage_area variable

```{r class.source = 'fold-hide'}
train %>% 
  ggplot(aes(x = garage_area, 
             y = log(sale_price))) +
  geom_point(alpha = 0.6) +
  labs(title = "Before removing outliers")
```

* Outliers

```{r}
# outliers : garage_area > 1230,  3개
train %>% 
  filter(garage_area > 1230) %>%
  DT::datatable(width = "100%",  
                options = list(scrollX = TRUE))
# outliers remove
train %<>% filter(garage_area <= 1230)
```

```{r class.source = 'fold-hide'}
train %>% 
  ggplot(aes(x = garage_area, 
             y = log(sale_price))) +
  geom_point() +
  labs(title = "After removing outliers(3개)")
```

## 1st_flr_sf variable

```{r class.source = 'fold-hide'}
train %>% 
  ggplot(aes(x = x1st_flr_sf, 
             y = log(sale_price))) +
  geom_point(alpha = 0.6) +
  labs(title = "Before removing outliers")
```

* Outliers

```{r}
# outliers : x1st_flr_sf > 2500, 4개
train %>% 
  filter(x1st_flr_sf > 2500) %>%
  DT::datatable(width = "100%",  
                options = list(scrollX = TRUE))
# outliers remove
train %<>% filter(x1st_flr_sf <= 2500)
```

```{r class.source = 'fold-hide'}
train %>% 
  ggplot(aes(x = x1st_flr_sf, 
             y = log(sale_price))) +
  geom_point(alpha = 0.6) +
  labs(title = "After removing outliers")
```

# `all_data` combine

```{r}
all_data <- bind_rows(train, test)
names(all_data)[1:10]
```

## Ordinal data

```{r}
all_data %>% 
  select_if(is.character) %>% 
  select(contains(c("cond", "qual"))) %>% 
  names()
```
* I think `condition1` and `condition2` are norminal based on the description. 

```{r}
# exter_cond variable
# ExterCond: Evaluates the present condition of the material on the exterior
# Ex	Excellent Gd	Good TA	Average/Typical Fa	Fair Po	Poor
all_data %<>% 
  mutate(exter_cond = as_factor(exter_cond),
         exter_cond = fct_relevel(exter_cond,
                                  c("Po", "Fa", "TA", "Gd", "Ex")),
         exter_cond = as.numeric(exter_cond))
```


```{r}
# bsmt_cond
# BsmtCond: Evaluates the general condition of the basement
# Ex	Excellent
# Gd	Good
# TA	Typical - slight dampness allowed
# Fa	Fair - dampness or some cracking or settling
# Po	Poor - Severe cracking, settling, or wetness
# NA	No Basement
all_data %<>% 
  mutate(bsmt_cond = as_factor(bsmt_cond),
         bsmt_cond = fct_explicit_na(bsmt_cond,
                                     na_level="No"),
         bsmt_cond = fct_relevel(bsmt_cond,
                                 c("No", "Po", "Fa", "TA", "Gd", "Ex")),
         bsmt_cond = as.numeric(bsmt_cond))
```

```{r}
# bsmt_qual
# BsmtQual: Evaluates the height of the basement
# 
# Ex	Excellent (100+ inches)	
# Gd	Good (90-99 inches)
# TA	Typical (80-89 inches)
# Fa	Fair (70-79 inches)
# Po	Poor (<70 inches
# NA	No Basement
all_data %<>% 
  mutate(bsmt_qual = as_factor(bsmt_qual),
         bsmt_qual = fct_explicit_na(bsmt_qual,
                                     na_level="No"),
         bsmt_qual = fct_relevel(bsmt_qual,
                                 c("No", "Po", "Fa", "TA", "Gd", "Ex")),
         bsmt_qual = as.numeric(bsmt_qual))
```

```{r}
# GarageCond: Garage condition
# 
# Ex	Excellent
# Gd	Good
# TA	Typical/Average
# Fa	Fair
# Po	Poor
# NA	No Garage
all_data %<>% 
  mutate(garage_cond = as_factor(garage_cond),
         garage_cond = fct_explicit_na(garage_cond,
                                       na_level="No"),
         garage_cond = fct_relevel(garage_cond,
                                   c("No", "Po", "Fa", "TA", "Gd", "Ex")),
         garage_cond = as.numeric(garage_cond))
# Can you do map this?
```

## Correlation

```{r}
train %>% 
  select_if(is.numeric) %>% 
  drop_na() %>% 
  cor() %>% as.data.frame() %>% 
  rownames_to_column(var = "variables") %>% 
  select(variables, sale_price) %>% 
  arrange(desc(abs(sale_price)))
```

## New variables

```{r}
all_data %<>% 
  mutate(old = yr_sold - year_built,
         old_remodel = yr_sold - year_remod_add,
         house_area = gr_liv_area + total_bsmt_sf,
         total_area = house_area + garage_area,
         total_area_w_pool = total_area + pool_area,
         extra_area = lot_area - total_area_w_pool,
         overall_plus = overall_qual + overall_cond,
         overall_square = overall_qual^2 + overall_cond^2,
         overall_minus = overall_qual - overall_cond,
         overall_gr_grage_inter = overall_qual * garage_area * gr_liv_area)
```


# Preprecessing with `recipe`

## Missing values {.tabset .tabset-fade}

### General info.

```{r}
na_info <- all_data %>% 
  map_df(~sum(is.na(.))) %>% 
  pivot_longer(cols = everything(), 
               names_to = "variable",
               values_to = "na_count") %>% 
  arrange(desc(na_count))
na_info %>% DT::datatable(width = "100%")
```

```{r}
na_info %>% 
  filter(na_count > 4) %>% .[[1]] -> nacols
nacols
nominal_col <- all_data %>% 
  select_if(is.character) %>% 
  names()
col_w_unknown <- nacols[nacols %in% nominal_col]
col_w_unknown
nominal_col <- c(nominal_col, "ms_sub_class")
```

## Make recipe

```{r}
housing_recipe <- all_data %>% 
  recipe(sale_price ~ .) %>%
  step_rm(id) %>% 
  step_log(sale_price) %>%
  step_unknown(all_of(col_w_unknown)) %>% 
  step_modeimpute(all_nominal()) %>% 
  step_dummy(all_of(nominal_col)) %>% 
  step_meanimpute(all_predictors()) %>%
  step_normalize(all_predictors()) %>%
  prep(training = all_data)
print(housing_recipe)
```

## `juice` the all_data2 and split

```{r}
all_data2 <- juice(housing_recipe)
```

We are done for preprocessing. Let's split the data set.

```{r}
train_index <- seq_len(nrow(train))
train2 <- all_data2[train_index,]
test2 <- all_data2[-train_index,]
```

 # Split the train into validation and train

```{r}
set.seed(2021)
# validation_split <- validation_split(train2, prop = 0.7)
validation_split <- vfold_cv(train2, v = 5, strata = sale_price)
# actual split id stored in the following
# validation_split$splits[[1]]$in_id
# the whole point is that it's there and trust tidymodels :)
# head(validation_split$splits[[1]]$in_id)
```

# Set the tuning spec

```{r}
tune_spec <- linear_reg(penalty = tune(),
                        mixture = tune()) %>%
  set_engine("glmnet")
param_grid <- grid_regular(penalty(), 
                           mixture(),
                           levels = list(penalty = 100,
                                         mixture = 5))
```

# Set workflow()

```{r}
workflow <- workflow() %>%
  add_model(tune_spec) %>% 
  add_formula(sale_price ~ .)
```


# Tuning $\lambda$ and $\alpha$

Elestic net uses the loss function as follows;

$$\underset{\beta}{min}\left(y-X\beta\right)^{T}\left(y-X\beta\right)+\frac{\lambda}{2}\left(\alpha\left\Vert \beta\right\Vert _{1}+\left(1-\alpha\right)\left\Vert \beta\right\Vert _{2}^{2}\right)$$

This can be thought of as the mixture of the Lasso and Ridge regression loss function. $\lambda$ is related to penalty, $\alpha$ is related to the proportion of Lasso penalty in the loss function.

```{r}
library(tictoc)
doParallel::registerDoParallel()
tic()
tune_result <- workflow %>% 
  tune_grid(validation_split,
            grid = param_grid,
            metrics = metric_set(rmse))
toc()
```

```{r}
tune_result %>% 
  collect_metrics()
```

# Visualization of the tunning result

```{r}
tune_best <- tune_result %>% select_best(metric = "rmse")
tune_best$penalty
tune_best$mixture
```


```{r message=FALSE}
tune_result %>%
  collect_metrics() %>%
  filter(mixture == tune_best$mixture) %>% 
  ggplot(aes(penalty, mean, color = .metric)) +
  geom_line(size = 1.5) +
  scale_x_log10() +
  theme(legend.position = "none") +
  labs(title = "RMSE")
```

```{r}
tune_result %>% show_best()
```

# Set Elastic net regression model and fitting

`mixture` parameter determines the proportion of Lasso regression in the Elastic net.

```{r message=FALSE, warning=FALSE}
elastic_model <- 
    linear_reg(penalty = tune_best$penalty,
               mixture = tune_best$mixture) %>%
    set_engine("glmnet")
elastic_fit <- 
    elastic_model %>% 
    fit(sale_price ~ ., data = train2)
options(max.print = 10)
elastic_fit %>% 
    tidy() %>% 
    arrange(desc(estimate)) %>% 
    filter(estimate > 0.001)
```

# Prediction and submit

```{r warning=FALSE}
result <- predict(elastic_fit, test2)
result$.pred <- exp(result$.pred)
result %>% head()
```

```{r, message=FALSE}
submission <- read_csv(file.path(file_path, "sample_submission.csv"))
submission$SalePrice <- result$.pred
write.csv(submission, row.names = FALSE,
          "elasticnet_tuned_w_outliersrm_group_old.csv")
---
title: "Baseline model with Tidymodels_adj0419"
author: "슬기로운통계생활_adj0419"
date: "4/6/2021"
output: html_document
---

# 원출처 : [슬기로운 통계생활](https://www.youtube.com/c/statisticsplaybook) at DACON!

안녕하세요~! R 사용자들의 데이터 경진대회 참여율을 높이기 위해서 baseline 코드 공개합니다. 요즘 핫한 Tidymodels를 사용해서 월간 데이콘 14 - 신용카드 사용자 연체 예측 AI 경진대회 베이스라인을 잡아보도록 합시다.

[슬통 캐글 R 스터디](https://www.youtube.com/playlist?list=PLKtLBdGREmMlJCXjCpCi5B4KQ-TsFvAAi)에도 많은 관심 부탁드립니다! R유저 화이팅~! 😎

# 준비작업

## 패키지 불러오기

이번 포스팅에서 사용할 R패키지들을 불러오자. 특히 요즘 핫하디 핫한 `tidymodels` 사용하여 월마트 대회를 가지고 놀아본다. 또한 마이 빼이보릿 연산자들을 사용하기 위하여 `magrittr`를 불러왔다.

```{r}
library(magrittr)
library(tidymodels)
library(tidyverse)
library(skimr)
library(knitr)
theme_set(theme_bw())
```

## 데이터셋 불러오기

이 대회에서 주어진 데이터셋을 불러보자. 주어진 파일 리스트는 다음과 같다.

```{r}
file_path <- "./dacon-credit-14/input/daconcredit14/"
files <- list.files(file_path)
files
```
각 변수의 이름을 `janitor` 패키지로 말끔하게 바꿔준다.

```{r}
train <- read_csv(file.path(file_path, "train.csv")) %T>% 
  suppressMessages() %>% 
  janitor::clean_names()
test <- read_csv(file.path(file_path, "test.csv")) %T>%
  suppressMessages() %>% 
  janitor::clean_names()
```


# 데이터 기본정보 확인

```{r}
train %>% 
  head() %>% 
  kable() %>% 
  kableExtra::kable_styling("striped") %>% 
  kableExtra::scroll_box(width = "100%")
```

## 기본 정보

이 대회는 기본적으로 간단한 대회이다. 첫번째 스터디용 대회로 선택을 한 이유이기도 하다. 주 데이터는 2만 6천개의 train 표본과 1만개의 test 표본들로 구성이 되어있다.

```{r}
dim(train)
```

```{r}
dim(test)
```

각 데이터 셋의 변수명을 살펴보자. 

```{r}
names(train)
```

```{r}
names(test)
```

먼저 `test` 데이터에는 우리가 예측하고 싶은 변수인 `credit` 변수가 들어있지 않은 것을 알 수 있다. 

데이터를 훑어보기 위해서 `skim()` 함수를 이용하자. 이 함수는 데이터에 들어있는 변수들을 타입 별로 분석해서 리포트를 작성해준다.

```{r}
skim(train)
```

결과를 살펴보자. 먼저 결측치가 상대적으로 많이 없는 착한? 데이터이다. character 변수의 complete rate를 살펴보면 모든 변수가 1이고, `occyp_type` 변수만이 결측치가 8171개가 존재하는 것을 알 수 있다. 또한 고맙게도 numeric 변수의 결측치는 하나도 없다!😆

같은 함수를 사용해서 `test` 셋을 보면 똑같은 패턴을 가지고 있는 것을 알 수 있다.

```{r}
skim(test)
```

# 시각화

베이스 라인을 잡은 문서이니 간단하게 시각화 하나만 하고 넘어가자. (코드를 응용해서 다른 변수에 대한 상관 관계를 볼 수 있을 것이다.)

```{r}
train %>%
  ggplot(aes(x = factor(credit), y = income_total)) +
  geom_boxplot() +
  facet_grid(. ~ income_type)
```

목표 변수인 credit은 낮을 수록 높은 신용의 신용카드 사용자를 의미 한다고 한다. Commercial associate 인 경우 신용이 제일 낮은 그룹의 수입의 중앙값이 제일 높다. 돈을 많이 벌수록 돈 갚은 개념이 없어지는 것인가? 재미있는 현상이다. 학생 클래스의 경우 train 데이터에 셋이 많이 없다는 것을 알 수 있다. 추후에 다른 클래스로 통합을 시키는 것이 좋을 것이다.



# <추가> Outliers

```{r}
# outliers 
train %>% 
  filter(child_num > 5) %>%
  DT::datatable(width = "100%",  
                options = list(scrollX = TRUE))

# outliers remove
train %<>% filter(child_num <= 5)
```


# 전처리 하기

`tidymodels`에서는 전처리를 할 때 `recipe` 라는 패키지를 사용한다. 이 패키지에는 전처리를 하는 방법을 음식 레피시 처럼 적어놓는다고 생각하면 쉽다.


## 전처리 사항들

* 결과값인 credit 변수와 character 타입의 변수들을 factor 변수로 바꿔주자.
* 나이와 직업을 가진 기간을 년수로 바꿔준다.

## `recipe`를 통한 전처리 입력

```{r}
credit_recipe <- train %>% 
  recipe(credit ~ .) %>% 
  step_mutate(credit = as.factor(credit)) %>% 
  # age and employment period in yrs
  step_mutate(yrs_birth = -ceiling(days_birth/365),
              yrs_employed = -ceiling(days_employed/356)) %>% 
  step_rm(index, days_birth, days_employed) %>%
  step_unknown(occyp_type) %>% 
  step_integer(all_nominal(), -all_outcomes()) %>% 
  step_center(all_predictors(), -all_outcomes()) %>% 
  prep(training = train)

print(credit_recipe)
```

## `juice`를 통한 전처리 즙짜기

`juice()` 함수를 통해서 recipe에 입력된 전처리를 짜낸 데이터를 얻어온다.

```{r}
train2 <- juice(credit_recipe)
head(train2)
```

다음과 같이 결측치 없이 잘 코딩된 데이터를 얻었다는 것을 확인 할 수 있다.

```{r}
train2 %>%
map_df(~sum(is.na(.))) %>%
  pivot_longer(cols = everything(),
       names_to = "variable",
       values_to = "na_count") %>% 
  filter(na_count > 0)
```

전처리가 끝났다.


# 튜닝 준비하기

`validation_split()` 함수를 사용하여 평가셋을 분리한다. 한 단계 더 나아간 cross validation은 `vfold_cv()`함수에서 제공하니 찾아보도록 하자.

```{r}
set.seed(2021)

validation_split <- validation_split(train2, prop = 0.7 , 
                                     strata = credit)
```

## 튜닝 스펙 설정

랜덤 포레스트를 사용할 것이고, mtry와 min_n을 어떻게 정할지를 평가셋을 통해서 결정할 것이므로, `tune()`를 사용해서 tidymodels에게 알려주도록 한다.

```{r eval=TRUE}
cores <- parallel::detectCores() -1
cores

tune_spec <- rand_forest(mtry = tune(),
                         min_n = tune(),
                         trees = 1000) %>% 
    set_engine("ranger",
               num.threads = cores) %>% 
    set_mode("classification")

# param_grid <- grid_latin_hypercube(finalize(mtry(), x = train2[,-1]),
#                                    min_n(), size = 100)

# from param tune
param_grid <- tibble(mtry = 3, min_n = 5)
```

## 워크 플로우 설정

```{r }
workflow <- workflow() %>%
  add_model(tune_spec) %>% 
  add_formula(credit ~ .)
```

# 모델 튜닝 with tune_grid()

# Tuning trees

```{r tune-grid, message=FALSE}
library(tictoc)
tic()
tune_result <- workflow %>% 
  tune_grid(validation_split,
            grid = param_grid,
            metrics = metric_set(mn_log_loss))
toc()
```

```{r eval=TRUE}
tune_result$.notes
tune_result %>% 
  collect_metrics()
```

# 튜닝결과 시각화

```{r message=FALSE, eval=TRUE}
tune_result %>%
  collect_metrics() %>%
  filter(.metric == "mn_log_loss") %>% 
  ggplot(aes(mtry, mean, color = .metric)) +
  geom_line(size = 1.5) +
  scale_x_log10() +
  theme(legend.position = "none") +
  labs(title = "Mean Log loss")
```

```{r eval=TRUE}
tune_result %>% show_best()
```

```{r eval=TRUE}
tune_best <- tune_result %>% select_best(metric = "mn_log_loss")
tune_best$mtry
tune_best$min_n
```

# 튜닝된 모델 학습하기

```{r trainrf, message=FALSE, warning=FALSE}
rf_model <- 
  rand_forest(mtry = tune_best$mtry,
              min_n = tune_best$min_n,
              trees = 2000) %>% 
    set_engine("ranger", seed = 2021, 
               num.threads = cores) %>% 
    set_mode("classification")

tictoc::tic()
rf_fit <- 
    rf_model %>% 
    fit(credit ~ ., data = train2)
tictoc::toc()

options(max.print = 10)
rf_fit
# Ranger result
# 
# Type:                             Probability estimation 
# Number of trees:                  1000 
# Sample size:                      26457 
# Number of independent variables:  18 
# Mtry:                             3 
# Target node size:                 5 
# Variable importance mode:         none 
# Splitrule:                        gini 
# OOB prediction error (Brier s.):  0.2308023 
```

# 예측하기

```{r warning=FALSE}
result <- predict(rf_fit, test, type = "prob")
result %>% head()
```

```{r, message=FALSE}
submission <- read_csv(file.path(file_path, "sample_submission.csv"))
sub_col <- names(submission)
submission <- bind_cols(submission$index, result)
names(submission) <- sub_col
write.csv(submission, row.names = FALSE,
          "dacon_credit_0419_4baseout.csv")
```

